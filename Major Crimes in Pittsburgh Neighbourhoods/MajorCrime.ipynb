{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e308c0fc-b50a-4959-803e-5c262eba616d",
   "metadata": {},
   "source": [
    "**Major Crimes in Pittsburgh Neighbourhoods**  \n",
    "Dataset: \"Arrests for Major Crimes, 1972\" (WPRDC)  \n",
    "File: 8ce92a4b-fa62-45c3-8cee-cc58fefede75.csv  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fce2472-34fa-4bee-8b2a-6da2cc536427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports (Also did !pip install (name), drop the ! if your doing it in terminal)\n",
    "import pandas as pd \n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sens\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea8d0b7-a9d3-4e2f-b84b-af363484c411",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the dataset\n",
    "crime = pd.read_csv(\"8ce92a4b-fa62-45c3-8cee-cc58fefede75.csv\")\n",
    "crime.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb79f7-e7d5-48c1-b600-62fb42a9d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accounting for complications with dataset\n",
    "\n",
    "#Accounting for blanks (filled with zero)\n",
    "crime = crime.fillna(0)\n",
    "\n",
    "#Determining the \"Weighted\" scale of each crime, kinda subjective\n",
    "\n",
    "crime['weighted_crime'] = (\n",
    "    crime['number_arrests_murder'] * 5 +\n",
    "    crime['number_arrests_rape'] * 4 +\n",
    "    crime['number_arrests_robbery'] * 3 +\n",
    "    crime['number_arrests_assault'] * 2 +\n",
    "    crime['number_arrests_burglary'] * 1.5 +\n",
    "    crime['number_arrests_larceny'] * 1\n",
    ")\n",
    "\n",
    "# Sorts by the highest to lowest weighted crime score (that I assigned above)\n",
    "\n",
    "crime_sorted = crime[['neighborhood', 'weighted_crime']].sort_values(\n",
    "    by='weighted_crime', ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "#Display stuff\n",
    "print(f\"Total Neighborhoods: {crime.shape[0]}\")\n",
    "print(crime_sorted.to_string(index=False))\n",
    "\n",
    "print(\"\\nNote: Higher weighted crime scores indicate that the neighborhood has more frequent severe crimes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415d6645-e061-4eec-87c7-6a6236603ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "#Nodes Nodes Nodes!\n",
    "for _, row in crime.iterrows():\n",
    "    G.add_node(row['neighborhood'], weight=row['weighted_crime'])\n",
    "\n",
    "\n",
    "#Edges\n",
    "\n",
    "for i, row_i in crime.iterrows():\n",
    "    for j, row_j in crime.iterrows():\n",
    "        if i < j:\n",
    "            similarity = 1 - abs(row_i['weighted_crime'] - row_j['weighted_crime']) / max(crime['weighted_crime'])\n",
    "            if similarity > 0.8:\n",
    "                G.add_edge(row_i['neighborhood'], row_j['neighborhood'], weight=similarity)\n",
    "\n",
    "#Graph visuals\n",
    "plt.figure(figsize=(16,12))\n",
    "pos = nx.spring_layout(G, seed=42, k=0.7)\n",
    "\n",
    "#Node colouring that vary based on the weighted crime levels\n",
    "node_weights = [crime.loc[crime['neighborhood'] == node, 'weighted_crime'].values[0] for node in G.nodes]\n",
    "node_sizes = [w / 2 for w in node_weights]\n",
    "node_colors = node_weights\n",
    "\n",
    "#Network itself\n",
    "nodes = nx.draw_networkx_nodes(\n",
    "    G, pos, node_size=node_sizes, node_color=node_colors, cmap=plt.cm.Reds, alpha=0.9\n",
    ")\n",
    "edges = nx.draw_networkx_edges(G, pos, alpha=0.4)\n",
    "labels = nx.draw_networkx_labels(G, pos, font_size=7, font_color='blue')\n",
    "\n",
    "#Titling and Colour Grades\n",
    "\n",
    "plt.colorbar(nodes, label=\"Weighted Crime Severity (See previous graph\")\n",
    "plt.title(\"Pittsburgh Neighborhood Major Crime Similiarity Graph\", fontsize=14)\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38849348-d06d-4281-bf49-d4da4b8fd614",
   "metadata": {},
   "source": [
    "**Explanation of Tables and Graphs**\n",
    "\n",
    "This particular dataset, titled “Arrests for Major Crimes, 1972,” records the number of arrests for serious crimes across 70 Pittsburgh neighbourhoods. Each crime type, including murder, rape, robbery, assault, burglary, and larceny, was assigned a severity weight so that I could calculate a single weighted crime score for each neighbourhood. The higher the score, the worse off the neighbourhood is in terms of crime.\n",
    "\n",
    "For the first table, I simply sorted the neighbourhoods using this weighted system. This helps visualise the data more clearly for someone unfamiliar with the neighbourhoods, since they do not need any prior knowledge of the area’s history or context, only the table itself.\n",
    "\n",
    "This actually leads into the next graph, which visualises the neighbourhoods as nodes within a crime similarity network, similar to the networking project. Neighbourhoods with similar crime patterns are connected and positioned close together, forming clusters that reflect how similar their crime severity levels are. It is important to note that the layout is not geographic and is purely based on similarity, which confused me at first even as the one who made it. Essentially, nodes that are positioned closer together have more alike crime profiles.\n",
    "\n",
    "I made this graph to address the limitations of looking only at the numbers in the table above. It can be difficult to grasp what those figures mean in reality. When you simply see a large number, you might assume the area is overwhelmed by crime, when in truth it may not be much higher than others with lower overall crime rates. Additionally, this method allows for the overlaying of other information, as you can look up the population of an area or any other metric and see if it lines up with other similar neighbourhoods in regards to those metrics.\n",
    "\n",
    "In addition, this type of graph is most ideal, as other graphs suffer from the same terrible tendencies that often confuse the onlooker. I originally considered something more akin to a bar graph but ultimately chose this due to the reasoning mentioned above.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92b11ab",
   "metadata": {},
   "source": [
    "**Conclusion**  \n",
    "\n",
    "Purely in terms of lowest crime rate the best neighbourhood from this dataset would be East Carnegie, it had the lowest score and was the most connected towards other neighbourhoods with consistent low crimes rates, additionally when you observe the tsv file you find it also has the lowest amount of \"low\" level crimes in terms of weight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4602271-d3ef-4213-8575-aef081d533f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
